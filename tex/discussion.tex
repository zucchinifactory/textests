\section*{Discussion}
%
\par
%
Next to the many qualitative observations we made, we used prominent, known features of spectra to calibrate the channel numbers.
We successfully detected the energies of the backscatter peak, the Compton edge and the photo peaks without significant errors compared to the theoretical values (deviation of about \SI{1}{\sigma} or smaller).
Here we note that the deviation is systematically larger for the Compton edge.
This is because the marked features are edges rather than peaks so the correct channel is much harder to find.
Still, we were able to verify the theoretical physical processes quantitatively.
Additionally, we proved the validity of common physical models, because the most probable transitions in the available decay schemes were detected.
The more detailed predictions, however, could not be reappraised due to the insufficient resolution of the used equipment and methods.
Longer experimentation and efforts of noise reduction could make future attempts more successful.
%
\par
%
Unfortunately, we were not able to make some of the supposed low energy observations.
The software was not able to record data for low channels.
Hypothetically, we could have detected a few peaks from secondary electron dis-excitations, especially in the $^{22}\text{Na}$ spectrum.
%
\par
%
The first coincidence measurement was conducted with $^{137}\text{Cs}$.
We wanted to correlate the detection of a Compton-scattered electron with the corresponding backscattered photon.
For a start, we were able to already show this with a very simple circuit (see figure \ref{fig:137Cskoinz1}).
Furthermore, we used more sophisticated methods to remove the random coincidence that occurred across the board.
Via combining two methods of energy and time selection, we were able to dramatically decrease the random coincidence, leading to the spectrum shown in figure \ref{fig:comptonpeak}.
There, we only see one strong peak of the Compton edge, proving the coincidence through prior detection of only backscattered photons.
However, in this model, we still rely on the assumptions, that the detectors only detect from a single direction and are lined up perfectly at an angle of $180^{\circ}$.
Since, in reality, satisfying these requirements isn't possible, there always is bound to be some random coincidence.
%
\par
%
We used the same techniques to examine the cascade decay of $^{60}\text{Co}$.
Apart from just showing the coincidence between the two emitted photons, we could use the detection rates from the measurements to calculate quantitative features such as source strength and detection probability.
These calculations are possible because one can assume, that the photon emission rate is independent of the angle concerning the decay of $^{60}\text{Co}$.
However, our calculated values deviate rather much from the theoretical value with about \SI{20}{\sigma}.
Still, the result is at least within one order of magnitude (off by a factor of $4$).
There are multiple reasons for the large deviation.
%
\par
%
We digitize and record our data with an \textbf{Analog to Digital Converter} (ADC).
Such a device always has a finite dead time $\tau$ after detecting an incoming signal.
If another signal follows in that time it will not be registered.
This changes the accepted detection rate $R_{\text{acc}}$ compared to the actual rate $R_{\text{in}}$.
Over a time corresponding to $\tau \cdot R_{\text{acc}}$ we do not record any additional photons.
The rate of additional incoming photons in that time can be calculated by multiplying with $R_{\text{in}}$.
We get:
\begin{align}
    \label{eq:DeadTime}
    \begin{split}
        R_{\text{in}} &= R_{\text{acc}} \cdot (1 + \tau \cdot R_{\text{in}} )
    \end{split}
\end{align}
%
However, as no sufficient value for $\tau$ was provided, the used detection rates could not be corrected.
The correction would increase the measured source strength because $Q$ scales linear with the rate.
%
\par
%
Furthermore, the theoretical value has to be seen with a grain of salt, as the given specification on the label of the sample box wasn't unambiguous.
The value we used for comparison could very well belong to another sample.
For future executions of this experiment, these values should first be verified.
%
\par
%
The other numerical value we were able to calculate is the theoretical random coincidence rate.
Again, the value is off by around \SI{20}{\sigma}.
This time, we suspect that the number of random events is determined in a flawed way.
If we're only counting events in the tolerable channel range, we get much better results.
This is due to the fact, that the software adds any counts exceeding the tolerance levels to the last channel.
Also, continuing the measurements for a longer period of time, we would expect better results for statistics improve and errors are reduced (see $\Delta N = \sqrt{N}$).
%
\par
%
While the coincidence time was calculated quantitatively, it is compared qualitatively only.
We clearly see, that the time resolution is much better for $^{60}\text{Co}$ than it is for $^{137}\text{Cs}$.
The utilization of the FWHM as a reference point doesn't really matter, as long as it is used for all samples the same way.
The observation correlates with the visible peak within the time spectra.
This is understandable considering the timescales of the coincidence of \SI{}{\nano\second} for the photon travel time compared to \SI{}{\pico\second} for the lifetime of the energy state.
%
\par
%
Overall, we successfully learned about working with scintillation detectors and utilized the coincidence method, while - at least qualitatively - making some very interesting and instructive observations.
